# 操作系统

## 操作系统基础

### 操作系统概述

- 操作系统的功能为：对硬件进行管理和抽象，为应用提供服务并进行管理。
  - 对硬件进行管理：把复杂且不同功能的硬件资源纳入统一管理。如操作系统把多种不连续的、有限的物理内存区域，使用物理内存分配器进行管理
  - 对硬件进行抽象：将有限的、离散的资源高效地抽象为无限的、连续的资源。如把物理内存抽象为统一的、近似无限的虚拟地址空间
  - 为应用提供服务：操作系统提供不同层次、不同功能的接口提供不同的服务
  - 对应用进行管理：操作系统对应用的生命周期进行管理
- 操作系统形态：操作系统内核和操作系统框架。
  - 操作系统内核：用于实现通用的、相对稳定的功能
  - 操作系统框架：面向不同应用场景进行适配，提供更有针对性的功能。操作系统框架也分为系统服务和应用框架
    - 系统服务：实现对操作系统内核抽象与管理能力的拓展
    - 应用框架：基于系统服务对应用开发与运行所需共性功能的增强
- 当只有一个应用，该应用直接控制硬件，是否还需要操作系统？
  - 答：可以不需要，这样做可以减少因操作系统对硬件的抽象造成的性能损失，理论上可以100%发挥硬件性能。但缺点是：一旦硬件发生改动，该应用往往也要随之改动。可以实现一套用于硬件资源管理与抽象的库，具有相对稳定的接口，并作为应用的一部分。当硬件发生改动时，只需修改这个库，无需修改应用。

### 操作系统结构

- 操作系统设计原则：将策略（Policy）（要做什么）与机制（Mechanism）（如何做到）分离

- 管理系统复杂性的方法：M.A.L.H方法，即模块化（Modularity）、抽象（Abstraction）、分层（Layering）和层次（Hierarchy）

  - 模块化：把复杂系统分解为一系列通过明确定义接口进行交互的模块，并严格保障模块之间的界限
  - 抽象：在模块化的基础上将接口与内部实现分离，从而使模块之间只需通过抽象的接口进行相互调用，而无须关心各个模块之间的内部实现。 
  - 分层：<u>不同类模块之间的层次化。</u>一个模块只能和同层模块以及相邻的上下层模块进行交互，而不能跨层和再上一级或再下一级的模块进行交互。
  - 层次：<u>同类模块之间的层次化。</u>

- 操作系统内核架构

  - 简要结构：

    - 应用程序与操作系统放置在同一个地址空间中，以同样的权限运行（内核态），没有内存管理、特权级隔离等功能。
    - 优点：应用程序对操作系统服务的调用无需切换地址空间和权限层级
    - 缺点：隔离能力弱，容易整个系统崩溃

  - 宏内核：

    - 系统分为内核态和用户态两层。内核：运行在特权级，集中控制所有计算资源。应用/用户态：运行在非特权级，受内核管理，使用内核服务。
    - Linux等就是宏内核
    - 缺点：（安全性与可靠性问题）模块之间没有很强的隔离机制（内核一旦某个模块出现问题，整个内核很可能出现问题）、（实时性支持）熊太复杂导致无法左最坏情况时延分析、（如Linux)系统过于庞大阻碍创新

  - 微内核：

    - 将操作系统的功能从内核中拆分出来，迁移到用户态，称为“服务”，服务与服务之间相互隔离，且服务之间采用消息传递机制通信（进程间通信,IPC）
    - 缺点：性能较差，内核中的模块交互由（宏内核）的函数调用变成了进程间通信

  - 外核架构：

    相比于传统架构，外核架构为不同应用定制不同的硬件抽象，把时间切片，操作系统内核在一个时间分片中只为一个应用提供服务，该应用可以使用所有硬件资源（而微内核中一个系统模块对应一个硬件资源，某硬件对应的该系统模块服务于所有应用）

    ![image-20230401163310701](操作系统.assets/image-20230401163310701.png)

    ![exokernel](操作系统.assets/exokernel.png)

    - 外核架构分为外核（Exokernel)和库操作系统(LibOs)

      - 外核在内核态，负责将计算资源与应用的绑定、资源的回收，同时保证多个应用之间的隔离

        - 具体功能：追踪计算资源的拥有权、保证资源的保护、回收到资源的访问权

          - 安全绑定(Secure binding)：

            将LibOS与计算资源绑定：允许某个LibOS访问某个计算资源（如物理内存），防止这些计算资源被其他LIbOS访问

          - 显示回收(Visible revocation)与中止协议(Abort protocol)：

            这是Exokernel与应用之间的协议。Exokernel显示告知应用资源的分配情况，应用在租期结束之前主动归还资源。如果应用不归还资源，则Exokernel强制中止（Exokernel拥有对资源的控制权，Exokernel主动解除资源与应用间的绑定关系）

      - 库操作系统(LibOS):LibOS提供对于硬件的抽象，与用户代码编译成一个二进制，在同一地址空间。而且LibOS可以修改定制，来适配上层用户对硬件的具体需求，如控制物理内存的相邻等等

        ![image-20230401171507432](操作系统.assets/image-20230401171507432.png)

  - 单内核架构(Unikernel)

    Unikernel是一种LibOS，它有着自己的哲学，那就是一个操作系统应该只有一个进程，内核和应用都在一个地址空间内。这样的好处就是，可以使得这个操作系统，或者说应用，非常地快。因为操作系统所有的资源都是这个应用的，而且所有对象都在一个地址空间里,还安全。



### 硬件环境与软件抽象

#### 程序的运行

从源代码到可执行程序：编译工具将文本格式的高级语言源代码翻译为汇编语言序列，再将汇编语言序列翻译为机器指令的序列，以二进制数据的形式保存在文件中，生成可执行的程序文件

指令：格式相对固定、功能相对简单、通常采用二进制编码

指令集架构(ISA)：对于机器指令的格式、行为以及处理器在执行中的状态的规范。即处理器向软件提供的接口。

内存：可视为一个大数组，每个元素为1个字节存储数据，每个元素对应一个地址

指令的两种执行模式：顺序执行和跳转执行

#### 处理数据

##### 寄存器

寄存器是处理器内部的存储单元，速度快，容量小。寄存器主要分为两大类：通用寄存器和特殊寄存器

- 通用寄存器：存储任意数据（ARM中为X0-X30），不同汇编指令通用寄存器的用法不同。
  - 注意：X0通常用于保存返回值和第一个参数
  - ARM中，X表示取完整的64位，W表示取低32位
  
- 特殊寄存器：保存特殊的数据。如X29保存栈帧指针(Frame Pointer,FP)

  PSTATE寄存器保存CPU的特权级状态

![image-20230402144101392](操作系统.assets/image-20230402144101392.png)

![image-20230402224428910](操作系统.assets/image-20230402224428910.png)

##### 处理器内部的数据运算和移动

汇编指令分为算术运算指令、逻辑运算指令、移位和数据搬移等指令

###### ARM常用数据处理指令

![image-20230402144727384](操作系统.assets/image-20230402144727384.png)

![image-20230402144851630](操作系统.assets/image-20230402144851630.png)

![image-20230402144926858](操作系统.assets/image-20230402144926858.png)

###### 寻址方式

寻址方式有立即数寻址、直接寻址、隐含寻址、间接寻址、寄存器寻址、寄存器间接寻址、基址寻址、变址寻址、堆栈寻址等，仅讨论其中一部分

**基址寻址**

定义：指令中给出一个寄存器号和一个形式地址，寄存器的内容为<u>基准地址</u>，形式地址是作为<u>偏移量</u>。
基准地址加上偏移量作为操作数的有效地址。

![image-20230402150401635](操作系统.assets/image-20230402150401635.png)

**变址寻址**

定义：指令给出一个寄存器号和形式地址，寄存器的内容作为<u>偏移量</u>，形式地址作为<u>基准地址</u>。基准地址加上偏移量得到有效地址。

注：#加数字表示这是一个立即数，不加#也可以（视具体编译器实现而定）

![image-20230402150446393](操作系统.assets/image-20230402150446393.png)

**前变址寻址方式**

![image-20230402150557245](操作系统.assets/image-20230402150557245.png)

**后变址寻址方式**

![image-20230402150618808](操作系统.assets/image-20230402150618808.png)

##### 条件结构：程序分支和条件码

###### 标签和分支指令

- 标签：为了实现程序的跳转执行，汇编语言中设有标签(如".L3")，用于定位某处汇编代码或数据的地址，对它们的引用会在汇编程序到可执行程序的转变过程中被翻译为真实的地址，而它们本身不会出现在可执行程序中
- 分支指令：主要为bne类（根据前一条指令的状态作为判断条件）和cbz类（根据本条指令内置计算的执行状态作为判断条件）。
  - 如bne(branch not equal)：前一条指令运算结果与零不相等时跳转
  - 如cbz(Compare branch zero)：cbz w1, .L1表示w1的值为零时会跳转到“.L1"

###### 条件判断与条件分支

对于bne类指令，为了记录前一条指令的执行状态，用条件码(Condition Flag)表示每次条件计算的特征，用状态寄存器记录程序运行状态，其中几位用来记录条件码

##### 函数调用、返回与栈

函数调用与返回：包含了ISA提供的函数调用指令和返回指令、函数运行时的数据需要占用的部分内存由运行时栈提供，并在函数实例返回时释放内存。

###### 函数调用和返回指令

被调用函数返回时，需要知道调用函数接下来要执行的指令的地址。调用函数调用时，也需要知道被调用函数的第一行代码的地址。

为了实现后者，只需要利用前面所说的跳转执行，将被调用函数名作为标签传递给调用函数跳转执行即可。

为了实现前者，由于被调用函数可能被多个调用函数调用，相应返回的地址也各不相同，因此需要保存调用函数的返回地址，返回地址为调用函数调用指令后的下一条指令。

综上分析：调用指令包含了<u>跳转到目标函数</u>和<u>保存返回地址</u>两个操作。

不同架构保存返回地址的方式不同。

- x86架构：将返回地址保存到内存，再从同一个内存位置读取返回地址，并跳转到要返回的代码处

- ARM架构：用特殊的寄存器保存返回地址，返回时再从寄存器中读取返回地址并跳转，这个寄存器叫做返回地址寄存器，即X30寄存器，别名为LR（Link Register)

  由于保存在寄存器中，如果被调用函数中调用了其他函数，则LR的值需要更新，原LR的值需要保存在内存中，返回时再将LR的旧值从内存中恢复。

  当然，如果被调用函数中没有调用其他函数，则LR的值不需要更新，也就不需要进行LR的值的存储和恢复

###### 运行时栈

保存函数中的局部状态（局部变量、实参等）

栈指针（Stack Pointer）指向运行时栈的栈顶

栈帧(Stack Frame)：每个函数在栈上拥有的连续内存空间

帧指针(Frame Pointer)：指向当前函数的栈帧在内存中的起始位置，保存在帧寄存器(x29)

<u>注意：</u>

- <u>FP在函数执行过程中是不变的，在x86架构中，函数执行时会动态分配和释放栈帧空间，因此SP会移动，在x86架构中，SP-FP为函数的栈帧空间；而在ARM架构中，编译器在函数开头就将所有栈内存分配完成，因此SP的值不会改变。</u>
- 调用函数的FP保存在被调用函数的栈帧中，因此能够实现栈追踪(Stack Trace)，即从当前函数开始往前追溯出调用链中每个函数的栈帧，并通过偏移量获取栈帧中的局部状态。
- FP也在寄存器中，每个函数在覆盖之前需要保存，之后再恢复

###### 函数的调用实例

为了避免调用者存放在通用寄存器中的值被覆盖，调用惯例将通用寄存器的划分为两部分：调用者保存(Caller-saved)或被调用者保存（Callee-saved)

调用者保存：调用者在调用函数前保存一些通用寄存器的值，将通用寄存器腾出给被调用者随意使用

被调用者保存：由于一些通用寄存器的值需要在调用前后保持一致，因此被调用者修改这些寄存器的值之前先保存旧值，返回时恢复旧值

（ARM中X9-X15由调用者保存，X19-X28由被调用者保存）

###### 数据传递

X0-X7用于传递前8个参数，X0能够传递返回值，更多的参数则保存在栈上（参数构造区）

低优化等级会让每个函数将每个实参存在栈帧中的参数保存区，高优化等级则选择用被调用者保存的寄存器(X19-X28)保存参数



## 虚拟内存

### 引言

- 应用进程在运行期间仅使用虚拟地址，访问物理内存使用物理地址
- 虚实地址转换（地址翻译）由CPU和操作系统配合完成。
  - 操作系统为不同的应用制定不同的地址翻译规则（页表）
  - CPU根据地址翻译规则（页表）将每条访存指令的虚拟地址翻译成物理地址，再通过总线将物理地址发送给物理内存，进行读写操作

### CPU的职责：内存地址翻译

- 物理内存中，每个物理地址对应一个存储单元，每个存储单元存储长度为1个字节

- **地址翻译**：将虚拟地址转换为物理地址。一个虚拟地址对应一个物理地址，对应一个存储单元

- **CPU中与地址翻译有关的重要部件**：内存管理单元（Memory Management Unit, MMU）和转址旁路缓存（Translation Lookaside Buffer, TLB）

  - MMU负责将虚拟地址转换为物理地址，即地址翻译
  - TLB负责加速地址翻译

- MMU可支持不同**地址翻译机制**，最常见的是**分页机制**（x86结构还有分段机制，但已经不那么常见了）：

  - 基本思想：将应用进程的虚拟地址空间划分为连续的、等长的虚拟页，同时将物理内存的物理地址空间也划分成对应的连续的、等长的物理页，虚拟页和物理页页长固定且相等。操作系统为每个应用进程创建从虚拟页到物理页的映射关系表，即页表。

  - 页表机制：虚拟地址由两部分组成：**第一部分**标识虚拟地址的**虚拟页号**，**第二部分**标识虚拟地址的页内偏移。由于虚拟页与物理页一一对应，因此虚拟地址的页内偏移就是物理地址的页内偏移。MMU翻译过程为：读取虚拟地址的虚拟页号，根据页表获得对应的物理页号，**物理页号加上虚拟地址的页内偏移就是物理地址**，从而完成地址翻译。

  - **不同应用进程对应不同的页表**（虚实地址映射表），因此不同应用进程的同一虚拟地址可对应不同的物理地址，实现虚拟地址空间的连续性和统一性。

  - 页表的基地址存放在CPU的特殊寄存器——页表基地址寄存器（*注意：存储在页表基地址寄存器的页表基地址是**物理地址***）。当操作系统切换应用程序时，通过**切换页表基地址寄存器存储的页表基地址（即切换页表）**即切换页表即可完成不同进程的虚拟地址空间切换。

    ![image-20230614194413563](操作系统.assets/image-20230614194413563.png)

- **多级页表：**

  - 目的：压缩页表大小

  - 原理：将虚拟地址的虚拟页号部分进一步细分——根据划分为**k级页表**的需求，**将虚拟页号划分为k个部分，其中第i个部分为对应的第i级页表的索引（页内偏移），当某一级的页表条目为空，该条目对应的下一级页表不需要存在**，因此多级页表只存储需要使用的页表，而单级页表需要每一项都实际存在。

    - 具体实现：一个64位的虚拟地址在逻辑上被划分为以下几个部分：

      - 63~48位：全为0或全为1（硬件要求）。应用进程使用的虚拟地址63-48位都是0，也说明应用进程的虚拟地址空间最大为$2^{48}$字节
      - 47~39位：第0级页表的索引值，即虚拟页号划分后的第一部分（虚拟页号$_0$）
      - 38~30位：第1级页表的索引值，即虚拟页号划分后的第二部分（虚拟页号$_1$）
      - 29~21位：第2级页表的索引值，即虚拟页号划分后的第三部分（虚拟页号$_2$）
      - 20~12位：第3级页表的索引值，即虚拟页号划分后的第四部分（虚拟页号$_3$）
      - 11~0位：页内偏移（页面大小为4KB，对应地址空间为$2^{12}$，对应页内偏移长度为12位）
      - 寻址过程：MMU根据页表基地址寄存器获取某应用进程的页表基地址，将虚拟页号$_0$作为0级页表的索引读取0级页表的对应的页表项，获得该页表项对应的1级页表的**物理基地址**；将将虚拟页号$_1$作为1级页表的索引读取1级页表的对应的页表项，获得该页表项对应的2级页表的**物理基地址**；将虚拟页号$_2$作为2级页表的索引读取2级页表的对应的页表项，获得该页表项对应的3级页表的**物理基地址**；将虚拟页号$_3$作为3级页表的索引读取3级页表的对应的页表项，获得该页表项对应的**物理内存的物理页号，配合虚拟地址的页内偏移，获得物理地址**

      ![image-20230614194545857](操作系统.assets/image-20230614194545857.png)

  - 注意：

    - 第i级页表的页表项对应第i+1级页表，每级页表项存储的是下一级页表的**物理基地址**（**第3级页表项存储的是物理内存的物理页号**）
    - 多级页表不一定能减少页表占有的空间。只有应用进程使用的虚拟地址空间**远小于**总的虚拟地址空间，多级页表才能减少页表占有的空间。
    - 64位CPU常见的配置是48位的物理地址和虚拟地址，每个页表项为8字节，1个4KB的页可保存512（$2^9$）个页表项，对应4级页表（48=9+9+9+9+12)；32位CPU常见的配置是32位的物理地址和虚拟地址，每个页表项为4字节，1个4KB的页可保存1024（$2^{10}$）个页表项对应2级页表（32=10+10+12)

- **页表项和大页**

  - AArch64体系中，每个页表项占用8字节

  - 页表项指向**下一级页表页**（实际上页表页也是物理内存页，但其中存储着页表项，不是空白的物理内存页，所以不称之为物理页）或者是**物理页**；如果**中间级**的页表项指向的不是下一级页表页，则该页表项指向的物理页称为**大页**。<u>注意：虚拟大页映射同样大小的物理大页，且大页仍然是若干个由4KB物理页基本单位组成</u>
    - 假设四级页表，第四级的物理页为4kB，往上一级（第三级）的大页为2MB（一个页表存储512个页表项，故大页大小为512x4kB)，第二级的大页为1GB（512x2MB)，第一级的大页为512GB(512x1GB)

  - 页表项存储**物理页号**（下一级页表页或指向的物理页）和**属性位**，这些属性位允许操作系统设置诸如读写执行等权限。
    - **物理页号PFN**：（以下举例为4级页表）
      - 若某页表项PFN指向4KB物理页，则该页表项称为**页描述符**
      - 若某页表项PFN指向下一级页表页（页表基地址），则该页表项称为**表描述符**
      - 若某页表项PFN指向512GB、1GB、2MB的大页，则该页表项称为**块描述符**
      - 若0级，1级，2级的页表项的第一位为1，则页表项为表描述符；若第一位为0，则页表项为块描述符

    - **UXN（Unprivileged eXecute Never)**，表明用户态代码对此页是否具有可执行权限
      - UXN为1，表示不具有可执行权限
      - UXN为0，表示具有可执行权限

    - **PXN（Privileged eXecute Never)**，表明内核态代码对此页是否具有可执行权限
      - PXN为1，表示不具有可执行权限
      - PXN为0，表示具有可执行权限
    - **AF（Access Flag)**：
      - AF为1，不会触发该访问异常
      - AF为0，若MMU查询到该页表项（CPU第一次访问相应虚拟页）时会触发一种访问异常：**访问标志位异常**（Access Flag Fault)

    - **AP（Access Permission）**：控制不同特权级（EL0和EL1）对页面不同的读写权限。如果实际访问需要的权限违背AP所表示的访问权限，触发一种访问异常：**访问权限异常**
    - **V（Valid）**，表示该页表项是否有效
      - 若V为0，触发**缺页异常**
      - 若V为1，能够进行地址翻译

- **TLB：页表的缓存（用于加速页表查询）**

  - TLB作为缓存，比内存读取速度快很多，但容量也小很多。TLB中存储虚拟页号到物理页号的映射关系，类比于哈希表的键值对，虚拟页号为键，物理页号为值。

  - 地址翻译时，首先会把虚拟页号作为键查询TLB中的缓存项，若找到直接获得对应的物理页号，称为TLB命中，则不需查询页表；若没找到，称为TLB没命中，则查询页表，找到页表项后，将翻译结果填写到TLB中。如果TLB已满，根据硬件制定的策略替换某一项。

  - 操作系统在进行页表切换时（应用进程切换时），会主动刷掉TLB，即TLB刷新。

  - 如果为了切换应用进程时不刷掉TLB导致性能损失，则采用打“标签”的方式。

    - AArch64体系结构中，操作系统为不同应用进程分配不同的地址空间标识（ASID）作为应用进程虚拟地址空间的标签，并将其写入应用进程页表基地址寄存器中的原空闲位，同时TLB也会包含ASID，以便将TLB中属于不同应用进程的缓存项区分开。**MMU翻译时，只需要比较TLB缓存项中保存的ASID与TTBR0_EL1中保存的ASID是否一致，只有一致才会使用该TLB。**
    - 如果ASID分配完，刷新所有TLB，重新分配ASID

    如果采用“标签”的方式，当**页表内容被修改后，操作系统仍然要主动刷新TLB以保证TLB缓存与页表项内容一致。**

  - 刷新TLB也有不同粒度。

- **关于分段机制有个补充：分段机制会导致外部碎片！！！**

### 操作系统：管理页表映射

- CPU上电启动后，由于MMU的地址翻译功能仍未启动，系统和应用进程会默认使用**物理地址**。操作系统负责在初始化过程中启动MMU的地址翻译功能，之后系统和应用进程使用的都是**虚拟地址**。
- 操作系统除了为应用进程配置页表，也需要为自己配置页表。AArch64中，操作系统自己使用的页表高16位为1，应用进程使用的页表高16位为0。操作系统自己有自己页表的页表基地址寄存器TTLBR1_EL1，在运行过程中，一般情况下，该寄存器内的值不变；应用进程使用另一个页表基地址寄存器TTLBR0_EL1，切换进程时，该寄存器的值要更改为新进程的页表基地址。
- 直接映射：
  - **操作系统一次性将全部物理内存映射到虚拟地址空间中**
  - 具体映射方式：虚拟地址=物理地址（物理基地址）+固定偏移

#### 映射策略

主流映射策略包括立即映射和延迟映射

##### 立即映射

- 创建进程时，操作系统直接在进程的页表中配置虚拟地址到物理地址的映射页表
- 进程执行时，如果虚拟内存区域不够用，操作系统直接分配新的物理页，并且更新页表项，配置对应的虚拟地址对物理地址的映射

##### 延迟映射

- 无论在进程创建还是进程运行时，先记录为应用进程分配的虚拟内存区域，但不分配相应的物理内存，此时没有映射（即有页表项，但页表项没有对应的物理页号，且V=0）。当应用进程访问某个虚拟页，虚拟地址对应的页表项V=0，此时CPU触发缺页异常，操作系统在缺页异常处理函数中为该虚拟页分配物理页，并在页表中填写映射（即虚拟地址对应的页表项填写物理页号，使V=1）

### 虚拟内存扩展功能

#### 共享内存

- 共享内存：允许同一个物理页在不同的应用进程间共享（不同进程的不同虚拟页映射到同一物理页）
- 写时拷贝：
  - 多个应用进程以**只读**的方式共享同一段物理内存。
  - 当某个应用程序想要对该内存区域进行修改，会触发访问权限异常（与AP位有关），异常触发后，CPU将控制流传递给操作系统的异常处理函数，操作系统会将异常对应的物理页重新拷贝一份，将新拷贝的物理页以**可读可写**的权限提供给触发异常的应用程序（只拷贝修改部分所在的物理页，其余部分仍然是只读方式共享）

#### 大页

- 能够大幅减少TLB的占用量（相比于4KB页的缓存项，相同内存下大页对应缓存项更少，从而提高TLB的命中率）
- 减少页表的级数，提高查询页表的效率

## 物理内存

### 引言

- 内存目标和评价维度：

  追求更高的内存资源利用率，追求优秀的性能（降低分配延迟和节约CPU资源）

- 内存碎片：无法被利用的内存

  - 外部碎片：**无法使用**的内存空闲部分（**未被分配**，在分配的内存块之间）
  - 内部碎片：分配的内存空间大于实际分配请求所需要的内存空间时，**被分配但未被利用**的内存空闲部分为内部碎片

## 进程

## 

## 同步原语

（对应课本“并发与同步”和“同步原语”）

### 同步问题的背景

#### 场景一：共享资源互斥访问（互斥问题）

多个线程需要同时访问同一共享数据时，应用程序需要保证其互斥性才能避免数据竞争，保证程序正确性

#### 衍生场景一

多个线程需要访问同一共享数据，但有多个线程只会读取共享数据不执行写操作，允许这些线程并行执行不会造成数据竞争

#### 场景二：条件等待与唤醒（同步问题）：

当线程需要等待某条件达成才能继续执行时，其应一直被阻塞。直到条件达成，唤醒该线程

#### 场景三：多资源协调管理

当多线程应用中存在多个资源可以被多个线程消耗或生产时，需要协调这些线程有序获取资源或者等待。此时等待的条件就是有可用的资源，唤醒的时机就是有线程产生资源

### 四种同步原语：

#### 互斥锁：

- **对应同步场景一**
- **保证只有一个线程在临界区内，主要面向两个线程**
- 我们将申请进入临界区设计为获取一把锁（lock）
  - 如果有空闲的锁，即没有线程在临界区内执行，则当前线程获取锁成功，并进入临界区
  - 如果没有空闲的锁，即有线程在临界区内执行，则当前线程阻塞等待，直到有锁释放，当前线程才能够获得锁，并进入临界区
- 同样的，标识退出临界区设计为释放一把锁（unlock），当前线程欲退出临界区时，将锁传递给下一个申请进入临界区的线程

##### 原子操作实现互斥锁：

- **原子操作介绍**：

  常见的原子操作有CAS和FAA（以下原子操作代码仅表示原理，实际执行是通过硬件实现）

  - **CAS:**

    CAS(lock,0,1)的意思是：如果lock的值等于0，则将lock赋值为1，返回原来lock的值0；如果lock的值不等于0，则返回原来lock的值1

    即比较lock的值与期望值，如果lock的值与期望值相同，则对lock进行相应的赋值操作；CAS返回的值永远是原来lock的值

    比如说我们将lock空闲状态设为0，使用状态设为1.

    如果当前lock的值为1，表明锁正在被使用，CAS(lock,0,1)判断lock没有处于空闲状态，不会对其赋值，并且返回lock当前的状态1（CAS(lock,0,1)!=0的意思就是判断当前lock是否处于空闲状态），则while(CAS(lock,0,1) != 0)会一直执行（循环等待）

    而当lock的值为0时，表明锁处于空闲状态，CAS(lock,0,1) != 0判断得到锁当前处于空闲状态，不再等待，进入临界区，同时为lock设为1，表示正在使用该锁

    *lock=0表示将锁重新设为空闲状态

    ![屏幕截图(7)](操作系统.assets/屏幕截图(7).png)

  - **FAA:**

    FAA(&var,2)意为：返回原var指向的值，并且对*var+=2操作

    ![屏幕截图(8)](操作系统.assets/屏幕截图(8).png)

- **原子操作实现**：

  - **自旋锁**

    可以保证互斥访问与空闲让进

    ➢ 优点：效率高，响应快

    ➢ 缺点：**不能保证有限等待**

    • 批准进入临界区过程很随意，不保证公平

    • 运气差的进程可能永远也不能成功，出现饥饿

    • while死循环太浪费CPU资源

    ![屏幕截图(5)](操作系统.assets/屏幕截图(5).png)

  - **排号自旋锁**

    可以保证互斥访问，空闲让进，有限等待

    lock：想要拿锁就要先拿排号，如果排号还没轮到，就循环等待；如果轮到，进入临界区

    unlock：叫号下一位等待者

    ![屏幕截图(6)](操作系统.assets/屏幕截图(6).png)

#### 读写锁

- **对应同步衍生场景一**

- 问题引入：假设有读者和写者，写者负责更新公告栏内容，读者负责读取公告栏内容，我们发现该背景下，同一时刻只能有一个写者更新公告栏内容，当该写者正在更新时，其他读者或者写者不能对公告栏阅读或更新，即**某个写者与其他读者和其他写者互斥访问**；而当公告栏完成更新后，可以允许多个读者对公告栏读取，即**读者与读者之间不存在互斥访问**

- 设计方法：**为读者配置”读者锁“（仅本人用于区分起的名字）(lock_reader和unlock_reader)，为写者配置”写者锁“（仅本人用于区分起的名字）(lock_writer和unlock_writer)**。读者锁和写者锁实现机制不同，从而实现“读者在执行读临界区代码时，保证没有写者执行写临界区，同时允许其他读者读临界区内容”和”写临界区既不允许其他读者进入读写锁保护的读临界区，也不允许其他写者进入读写者保护的写临界区“

- **读写锁的偏向性**

  情景：假设有读者正处于临界区中，临界区外有写者和多个读者在申请并等待进入临界区，当处于临界区的读者退出临界区时，如何决定谁是下一个进入临界区的人，这就是读写锁的偏向性问题。

  - 偏向读者的读写锁（并行性更好，读者可以一起看）：

    允许写者申请进入临界区之后的读者优先进入读临界区（即针对以上情景，等待的读者可以插在写者排的队之前进入临界区，所有读者读完了才到写者）

  - 偏向写者的读写锁（更公平，谁先排队谁先进）：

    阻塞在写者申请进入写临界区之后到达的读者（即针对以上情景，如果写者先排队，所有读者必须乖乖排队让写者先进；如果有读者在写者之前排队，则读者先进）

#### 条件变量

- **条件变量对应同步问题场景二**

- 条件变量并不是单独解决临界区问题的方法，而是基于原子操作中的自旋锁while操作浪费CPU资源的问题产生的优化方案：将某线程循环等待的**执行状态**转变为等待外界触发的**阻塞状态**，即循环等待条件转为阻塞等待条件（循环也能实现同步问题，但性能不够好）

  ![屏幕截图(9)](操作系统.assets/屏幕截图(9).png)

- 具体实现

  - **条件变量必须搭配互斥锁一起使用，互斥锁用于保证对条件的修改与判断**

  - struct cond为条件变量类型

  - cond_wait(struct cond* cond, struct lock* mutex)挂起当前线程以等待对应的条件变量

    **注意放锁操作一定要与挂起操作一起发生**，否则会发生”线程A提前放锁导致线程B获取锁更新条件并唤醒等待线程，而线程A在线程B唤醒时仍未处于挂起状态，从而错过了这次唤醒，等到线程A处于挂起状态时，可能不再有线程来唤醒线程A，导致错误

  - cond_signal(struct cond *cond)唤醒一个等待在该条件变量的线程

  - cond_broadcast(struct cond *cond)用于唤醒所有等待在该条件变量上的线程

#### 信号量（PV原语）

- PV原语中，P表示检验：对应接口wait；V表示自增，对应接口signal

- 信号量用于辅助控制多个线程访问有限数量的共享资源，信号量的初值应设置为初始共享资源的数量

- wait等待可用资源而阻塞，如果有可用资源，将可用资源数减一；signal增加资源数量并唤醒等待资源的进程

  ![屏幕截图(10)](操作系统.assets/屏幕截图(10).png)

#### 四种同步原语的联系和区别

- 互斥锁主要面向**两个线程**，信号量面向**多个线程**访问**有限数量**的**共享资源**
- 锁是线程自己添加自己释放，而条件变量和信号量是自己阻塞，其他线程唤醒或自己唤醒其他阻塞的线程
- 信号量阻塞的条件是共享资源的数量，而条件变量阻塞的条件包括但不仅限于共享资源的数量。
- 条件变量和信号量都能满足同步需求，但**条件变量使用场景更广泛，信号量只适用于特定场景**。在特定场景：生产者和消费者模型中，用“互斥锁+条件变量+计数器”能够实现信号量的功能，只是信号量更加方便易用；而在一般场景，例如事务处理场景中，如果处理线程等待事务到达后希望一次性拿走所有的待处理事务一并处理，使用信号量就很难实现——**因为信号量每次执行wait操作只能拿走其中的一个资源**

### 生产者/消费者模型

- 问题介绍：多个生产者线程，多个消费者线程，生产者不断地生产新的数据，消费者不断地拿取新的数据，它们之间通过一个有限容量的缓冲区共享数据

- 同步需求：

  - 数个生产者（消费者）之间需要协同：避免因共享缓冲区中的数据产生数据竞争而造成错误

    - 数据竞争：一个进程中多个线程同时访问同一个地址（共享内存），且其中至少有一个是写操作。如果发生数据竞争，则线程之间访存顺序不确定（读->写->读/写->读->读/...），导致最终执行结果不可预知

      （很多时候数据竞争是由于某个线程读写过程中被另一个线程打断造成线程之间访存顺序不确定，或者线程之间执行顺序访存顺序本来就不确定，总之就是因为线程之间访存顺序不确定）

  - 生产者与消费者之间需要协同：消费者需要在缓冲区为空时等待生产者生产数据，生产者在缓冲区满时等待消费者消费数据

- 解决方法：

  - 第一个需求通过共享互斥锁实现：生产者：加锁->生产数据->释放锁，生产者：加锁->消费数据->释放锁
  - 第二个需求通过共享变量empty_slot和filled_slot实现：生产者：加锁->生产数据(empty_slot--,filled_slot++)->释放锁，生产者：加锁->消费数据(empty_slot++,filled_slot--)->释放锁

### 临界区问题

- 问题要求：同一时间只有一个线程能执行临界区内的代码

- 临界区问题将程序分为四个部分：申请进入临界区（拿互斥锁）->执行临界区代码（临界区代码是对共享资源进行操作的代码部分）->标识退出临界区（释放互斥锁）->执行其他代码（与共享资源无关的代码）

- **解决临界区的三个要求**

  - **互斥访问**：同一时刻，最多只有一个线程进入临界区

  - **空闲让进**：没有线程在临界区时，必须选一个线程允许进入临界区

  - **有限等待**：当线程申请进入临界区时，必须在有限时间内获得许可

    （比如A在上厕所，B申请去上厕所，老师跟B许诺5min后A如果还没回来就让B去，B在5min之后必须能够获得许可）

    ![屏幕截图(3)](操作系统.assets/屏幕截图(3).png)

  - **解决方法：**

    - **硬件实现**：**单核**下，由于进程是按时间片调度的（超过时间片就会中断打断当前进程执行，调度其他进程），因此为了保证临界区中的进程能够顺利执行，我们需要在“申请进入临界区”时关闭中断，而在“退出临界区”时开启中断。但**多核**不适用，关闭中断不能干扰其他核心上正在运行的线程。

    - **软件实现**：皮特森算法（解决**两个**线程之间的临界区问题）

      - 由于皮特森算法严格依赖于指令的执行顺序（顺序执行），而现代的CPU往往允许乱序执行，因此**皮特森算法在现代无法使用**，如果实在要使用，需要加内存屏障。

      - 请注意每个线程while内第二行(turn=...)和第三行(while(flag[..]=..))的顺序

      - 以线程0执行为例，turn=1之后，while(flag[1]==TRUE&&trun==1)满足循环条件，将会一直循环，也就是说turn=1使得线程0将执行顺序谦让给线程1。线程1同理，也会将执行顺序谦让给线程0

      - 问题的关键在于对于共享变量turn的执行顺序：

        - 假设**线程0先执行（谦让）**，线程1后执行，那么turn=0，此时**线程0会优先进入临界区**，线程1进入等待
        - 假设**线程1先执行（谦让）**，线程0后执行，那么turn=1，此时**线程1会优先进入临界区**，线程0进入等待
        - 我们发现看似每个线程为另一个线程谦让进入临界区的资格，实则最终获取进入临界区的资格的该线程自己。并且由代码可知：**皮特森算法满足互斥访问，空闲让进，有限等待**

        ![屏幕截图(4)](操作系统.assets/屏幕截图(4).png)

    - **软硬件协同**：利用**硬件实现的原子操作（不可打断的一系列操作）**设计软件算法解决临界区问题

      x86：由于对地址的操作需要经过总线，因此原子操作通过**锁总线**来避免其他CPU进入临界区

      Linux：使用LL/SC实现

### 死锁

死锁：指这一组中的每一个线程都在等待组内其他线程释放资源而造成的无限等待

#### 产生死锁的原因

- 互斥访问：互斥访问保证一个共享资源在同一时刻只能被至多一个线程访问。在有互斥访问的前提下，线程才会出现等待
- 持有并等待：线程持有一部分资源，并等待一些资源
- 资源非抢占：一旦一个资源被持有，除非持有者主动放弃，其他竞争者都等不到这个资源
- 循环等待：在一系列线程T0，T1，……，Tn，其中T0等待T1，T1等待T2……Tn等待T0因此形成了一个循环。由于循环中任意一个线程都无法等到资源，因而不能释放已经占有的资源，因此出现了循环等待

**死锁并不是只有使用互斥锁时才会出现，只要满足以上四个条件，死锁就会出现**

#### 死锁解决方法

- 死锁检测与恢复：

  - 检测：系统通过**资源分配表**和**线程等待表**记录系统中资源分配与线程等待相关信息，根据这两张表画出对应的图，通过**图是否存在环判断是否出现了循环等待**，即死锁现象
  - 恢复：
    - 方法一：如果发现了死锁，找到这个环中任意一个线程作为受害者，直接终止该线程并释放其占有的资源。如果仍然成环，则重复该步骤，直到打破循环等待。（不太公平）
    - 方法二：让环上所有线程回退到之前的某一个状态再次运行（难以实现）

- 死锁预防（运行前）

  - 避免互斥访问。例如设计一个代理线程，用于管理对于共享数据的访问与修改。这个共享数据只能由代理线程操作，其他线程需要向代理线程发送请求来完成对共享数据的访问。（难以实现）
  - 不允许持有并等待。要求线程在开始操作之前一次性申请所有资源，一旦需要获取的资源中任一资源不可用，则该线程就不能成功申请这一系列资源，并且该线程必须释放已经占有的资源。（可能会出现活锁情况：即申请—释放的循环，但一直没有进入临界区）
  - 允许资源被抢占。允许一个线程抢占其他线程已经抢占的资源，被抢占的线程回滚到获取该资源之前的状态。（难以实现）
  - 避免循环等待。要求线程按照一定顺序获取资源，任一时刻系统中总有一个得到资源编号最大资源的线程，因此该线程一定能够拿到所有所需资源，因此该线程能够继续执行。

- 死锁避免（运行时）

  - 死锁避免在系统运行时跟踪资源分配过程来避免出现死锁。在系统运行时，任意线程需要新的资源时都必须向系统提出申请。系统将根据所处状态（安全状态或非安全状态），判断是否能够将资源分配给该线程

    - 安全状态：存在至少一个安全序列{T1，T2，T3…Tn}，如果系统按照这个序列执行，就能避免资源不足的情况发生
    - 非安全状态：没有安全序列（处于非安全状态不一定会导致死锁，只有线程必须获取所有所需资源才能结束且在此前不会释放已经占有的资源的前提下一定会导致死锁）

    死锁避免算法通过让系统每一次分配资源时都处于安全状态，如果分配之后不能处于安全状态，则不分配资源给线程

  - 经典方法：**银行家算法**（应用在调度器中，通过模拟分配资源后的状态判断分配某个资源后，系统是否还处于安全状态）

    - 数据结构

      - 全局可利用资源$Available[M]$。表示某一时刻系统中每一类元素的可用个数，初始化时Available[M]为系统中拥有的M类资源的总量
      - 每个线程的最大需求量$Max[N][M]$。该矩阵包含所有N个线程对M类资源的最大需求量
      - 已分配资源数量$Allocation[N][M]$。该矩阵包含已经分配给N个线程中每个线程的M类资源的数量
      - 还需要的资源数量$Need[N][M]$。该矩阵包含所有N个线程对M类资源的还需要的资源数量

    - 工作前提：

      - 系统中的供给关系是固定的。比如系统中的资源类别数M，线程总数N，整个系统中M类资源的可用数量，以及每个线程所需要的不同种类资源的数量，都必须是固定不变的。
      - 线程获得了所有需要的资源后，能在有限时间内完成工作，并且释放已经获得的资源

    - 工作过程：

      - 创建一个临时数组$AvailableSim[M]$，初始值与$Available[M]$一致，用于模拟分配资源。

        ![屏幕截图(24)](操作系统.assets/屏幕截图(24).png)

      - 找到当前系统剩余资源能够满足的线程

      - 假设将资源全部分配给它，它执行完成后会释放所有的资源，同时标记该线程执行结束

      - 遍历所有线程，查看是否还有未被标记执行结束的线程，如果有，回到第二步骤；否则代表系统处于安全状态，模拟完成，模拟的序列为安全序列，调度器按照该安全序列调度。

### 活锁

线程不断重复“尝试获取资源-失败-尝试获取资源-失败”的执行状态

![屏幕截图(23)](操作系统.assets/屏幕截图(23).png)

## 文件系统

### 块设备

- 由于硬件设备不同，一次读写大小与硬件相关，差异很大。因此**文件系统将存储设备抽象为一个以存储块为单位的大数组**

- 存储块是存储设备的**最小读写单元**，大小固定，**常见大小为512字节或4KB**，**每个存储块通过一个地址进行标识和索引**，该地址称为块号

  ![屏幕截图(25)](操作系统.assets/屏幕截图(25).png)

### 基于inode的文件系统

#### inode（index node）

- 本质：记录一个文件所在得存储块号（索引）。**一个文件与一个inode一一对应**

- 如果一个指针为8字节，那么一个Inode为256字节（128字节的元数据+128字节的指针）

- inode包括文件元数据和12个指针

  - 文件元数据

    包括文件类型，文件大小，权限，修改时间，访问时间等，**不包括文件名（文件名存在目录中）**

  - 16个指针（128字节）

    每个指针均为8字节，16个指针一般为**12个直接指针**（直接指向存储块），**3个间接指针**（每个指针指向一个4KB的索引块，索引块上每一条索引对应一个存储块，即每个指针对应512个存储块），**1个二级间接指针**（对应512*512个存储块）

    ![屏幕截图(27)](操作系统.assets/屏幕截图(27).png)

    ![屏幕截图(26)](操作系统.assets/屏幕截图(26).png)

#### 目录

- **目录是特殊的文件**，也拥有自己的inode，inode的每个指针对应的存储块内存有若干个**目录项**（**文件名**，文件名的长度，**文件名对应的inode**，目录项的长度）

  ![屏幕截图(28)](操作系统.assets/屏幕截图(28).png)

- **目录名存储在父目录的目录项中**，同理，第一级目录的目录名存储在根目录的目录项中，**根目录没有目录名（文件系统将第一个inode作为根目录文件）**

- 在目录中查找文件：文件系统从目录的数据块中记录的第一个目录项开始，将要查找的文件名与目录项记录的文件名依次比较，当要查找的文件名与目录项记录的文件名匹配时，返回对应的inode号

- 删除目录项：将目录项中的inode设为0。

  - 还可以将多个相邻的inode为0的被删除的目录项合并，允许更长的新目录项重新利用这些空间。

#### 存储布局

**格式化**：在存储设备上创建新的文件系统，文件系统格式化工具会根据文件系统的存储布局和存储设备的容量，计算每个区域的大小，并初始化区域中的元数据

- 基于inode文件系统将整个硬盘分为**超级块，块分配信息，inode分配信息，inode节点表，数据块**五部分
  - 超级块
    - 记录整个文件系统的全局信息。包括标识文件系统类型的magic number，版本信息，存储空间大小，能支持的最大inode数量，当前空闲可用的inode数量等等
    - 超级块包含的信息非常重要，在存储设备的不同区域保存多个备份
  - 块分配信息：位图（数组）标识对应的数据块是否使用（1表示使用，0表示空闲）
  - inode分配表：位图（数组）标识对应的inode是否使用（1表示使用，0表示空闲）
  - inode节点表：存储inode节点。不能动态调整，因此保存的inode节点数量固定，即**文件系统所能保存的最大文件数量格式化时就已经确定**
  - 数据块：电脑硬盘中显示的可用空间大小

![屏幕截图(29)](操作系统.assets/屏幕截图(29).png)

![屏幕截图(31)](操作系统.assets/屏幕截图(31).png)

- 
- 
  - 

### 基于表的文件系统

### 虚拟文件系统

### 用户态文件系统

## 文件系统崩溃一致性

### 崩溃一致性

- 创建一个新的常规文件过程

  1. 分配inode

     从inode分配表中查询空闲的inode（位为0），将对应的位标记为1，表示该inode已被使用

  2. 初始化inode

     对分配得到的inode进行初始化操作，即将新文件的信息保存在inode结构之中

  3. 增加目录项

     在父目录中添加新的目录项，新目录项保存新的文件名和对应的inode号

- 崩溃一致性：

  文件系统在完成一个接口时往往涉及存储设备上多处数据的修改，若执行这些修改的过程中发生掉电或崩溃的情况，那么一个文件操作可能只做到一半，即只有一部分修改被写入存储设备，这有可能导致存储设备所保存的数据之间的一些内在关系（一致性）受到破坏

  如下图，某操作持久化的意思是完成了对硬盘的某操作

  ![屏幕截图(32)](操作系统.assets/屏幕截图(32).png)

### 在线与离线恢复工具

- windows：chkdsk
- linux：fsck

### 原子更新技术

文件系统操作所要求的三个属性：持久化，原子性，有序性

- 日志（预写式日志）

  - 原理：

    - 在执行修改操作之前先在日志中记录修改的内容
    - 所有要进行的修改都记录完毕后，提交日志
    - 真正地对硬盘进行修改操作
    - 删除日志

  - 具体操作：

    - 创建：

      文件系统为日志分配内存和存储空间，并初始化维护日志所需的元数据

    - 写入：

      文件系统将要进行的操作或操作影响的数据及其所在位置写入日志中。

      由于操作数量较多或操作的数据量较大，在写入阶段记录的操作信息往往超出存储设备的原子写入大小，因而无法原子地写入存储设备中，也就是说当发生崩溃时，存储设备中处于写入阶段的日志内容可能是不完整的。

    - 提交：

      **文件系统将此前在日志中记录的操作信息原子地标记为有效**。在保证所有日志内容均已持久化在存储设备中之后，日志系统将在存储系统上原子地标记日志为已提交状态，并进入完成阶段。

      **提交之后日志才算有效，才能进行新修改的恢复。否则对之前的修改进行丢弃。**

    - 完成：

      文件系统将实际的修改写会存储设备中。即使此时完成阶段发生崩溃，恢复时也能根据日志内容进行恢复。

    - 无效：

      当文件系统已经完成所有需要进行的修改，并且保证这些修改已经持久化之后，将日志标记为无效。

      **无效的日志在恢复时不会进行恢复操作**

    - 销毁：

      日志无效后，文件系统可以对日志所占用的资源进行回收，即销毁日志

  - 日志内容

    - 重做日志

      将数据位置和此位置上即将被写入的新数据（即修改后的数据）保存在日志中。

      **<u>日志的成功提交标志着日志中修改的成功持久化</u>。即日志提交后，无论其修改是否已经写回原位置，这些修改操作都可以从日志中恢复**

    - 撤销日志

      在日志中记录数据位置和位置上原来保存的数据

      日志提交后，如果日志发生崩溃，日志系统会从日志中读取崩溃前可能修改的位置

      **<u>数据修改的持久化取决于日志是否标记为无效</u>，如果日志没有标记为无效，日志所记录的位置上的任何数据修改，均会在崩溃回复时回滚到日志刚提交时的状态**

    - 重做日志和撤回日志数据修改的持久化的标志不同，因为撤回只能撤回到最近一次修改，因为完成数据持久化的标志是不用再撤回，而写入操作可以多次写入，因此完成数据持久化的标志是日志完整地记录了操作。

  - 日志的批量化与合并优化

    - 如果每个文件系统操作之后都进行日志的提交，每个操作均会产生对存储设备的访问，影响性能。

    - 基于页缓存的延迟提交策略：

      在内存中记录日志，异步写入到磁盘中

      - 如果多份日志包含相关内容，日志内容可以进行合并，每个修改过的块只需记录一次
      - 日志提交：定期触发或用户调用接口触发

- 写时拷贝

  使用写时拷贝修改数据时，首先对原数据进行一次拷贝，并在拷贝出来的数据副本上进行修改。之后写时拷贝通过修改指向原数据的指针，使其指向新数据，从而使副本中的数据修改生效。

  ![屏幕截图(33)](操作系统.assets/屏幕截图(33).png)

  不论想要修改树中的多少个节点，最终都能将修改转变为对根节点的原子操作（向上递归写时拷贝），以保证整个树上所有修改均是原子完成的。

  原子更新的完成可以归结到一个原子操作上，即对**指向树根的指针的修改**，该原子操作称为**原子更新点，也为数据的原子持久化点。**

  ![屏幕截图(35)](操作系统.assets/屏幕截图(35).png)

  ![屏幕截图(34)](操作系统.assets/屏幕截图(34).png)

## 设备管理

#### 基本设备类型

- 字符设备
  - 顺序访问：每次读取一个字符
  - 调用驱动程序和设备直接交互
  - 使用文件抽象
  - LED，键盘，串口
    - 串口：收发双方使用相同波特率（数据传输速度）并且将彼此的Tx与Rx进行连接才能进行通信
- 块设备
  - 随机访问：以块粒度进行读写
  - 在驱动程序上增加一层缓冲，避免和设备频繁交互
  - 使用内存抽象(MMIO)直接访问数据
  - 磁盘、U盘、闪存（存储设备为主）
    - 机械硬盘：扇区（512字节）为最小读写单元
    - 闪存：页（4KB到512KB不等）为最小读写单元
- 网络设备
  - 使用套接字抽象
  - 以太网、蓝牙、WIFI

### 概述

- 设备驱动层：操作设备的代码集合，不同设备的驱动不同，操作系统与设备间能相互通信的特殊程序

- 设备管理的共性功能层：操作系统为设备的共同管理需求而沉淀出的统一抽象层

- 应用I/O框架层：为应用程序提供自主可定制的I/O管理能力，以共享库存在

  应用程序还可以直接绕过操作系统内核与I/O进行交互，例如DPDK库

  ![微信图片_20230630091942](操作系统.assets/微信图片_20230630091942-1688088027117-8.png)

- 总线分为系统总线和外设总线

  - 系统总线连接CPU和内存以及高性能的设备

  - 外设总线与网卡，显卡或其他相连

  - 外设总线类型：

    - AMBA总线：ARM结构特有

    - PCI/PCIe总线：PCI全称为设备组件互联标准（设备索引设计为总线号，设备号，功能号的组合（简称为B/D/F））

      PCIe总线比PCI总线数据传输带宽更高，同样采用B/D/F索引设备

### 设备的组成

- 外部接口：设备寄存器，作为设备操作的统一编程接口
  - 控制寄存器：用于向设备发送特定的控制指令
  - 数据寄存器：用于CPU和设备之间的数据交换
  - 地址寄存器：用于配置控制命令或数据读写所使用的具体地址
  - 状态寄存器：用于查询当前设备的工作状态
- 内部组成：
  - 微控制器:完成设备相关的特定逻辑
  - 内部存储：存放当前设备状态

### 设备寄存器的访问

#### 可编程I/O

可编程I/O（Programmed I/O,PIO):允许驱动的开发者根据需要编程设备的具体行为

PIO包含了端口映射I/O（Port-Mapped I/O,PMIO)和内存映射I/O（Memory-Mapped I/O,MMIO）

- 端口映射I/O（Port-Mapped I/O,PMIO)：
  - 采用独立于物理地址空间之外的特殊地址空间进行寻址
  - CPU需要使用特殊的I/O指令对设备寄存器进行读写
- 内存映射I/O（Memory-Mapped I/O,MMIO）
  - 物理内存和设备寄存器进行统一编址，在物理地址空间上给I/O设备分配一段专门的地址区域，用于映射设备寄存器
  - 运行在CPU上的操作系统通过访存指令直接操作设备寄存器，进而获取设备寄存器状态并对设备进行配置
  - 避免编译器的优化，使用volatile关键字
  - MMIO访问时插入内存屏障，保证设备寄存器的顺序执行

### 直接内存访问

- CPU与外设通信时，需要CPU从内存中读取数据，再将数据从CPU写到外设中
- 直接内存访问技术（Direct Memory Access,DMA)，允许硬件设备绕过CPU进行批量物理内存数据的读写
- 从而在硬件设备传输数据的时候，CPU可以执行其他任务，显著提高CPU的利用率
- CPU发起DMA为例：
  1. 操作系统在内存中分配一块DMA缓存区，随后发起DMA请求（通过MMIO的方式）（CPU向DMA控制器发送DMA缓冲区的位置和长度，以及数据传输的方向），随后放弃对总线的控制
  2. DMA控制器获得总线控制权
  3. DMA控制器根据从CPU获得的指令，通过DMA的方式将数据批量传输至DMA缓存区。DMA完成后，DMA控制器触发中断，通知操作系统对DMA缓存区中的数据进行处理，CPU重新获得总线控制器

### 中断

中断的分类

- IRQ：普通中断，优先级低，处理慢
- FIQ：一次只能有一个FIQ，快速中断，优先级高，处理快

中断控制器

- 中断号：映射设备到中断的关系。中断发生时，操作系统可以根据中断号快速判断中断来自哪个设备，并采用预定义的方式快速响应中断
- 中断屏蔽：保证CPU上某些操作的原子性。例如为了保证临界区操作的原子性，可以通过屏蔽时钟中断的方法， 防止当前任务被调走
- 中断优先级：用于区分更为重要或紧迫的中断

GIC中断控制器（ARM中的中断控制器）

- 分发器：汇聚所有设备的中断请求，并根据路由配置将中断分发给目标核心
- CPU接口：CPU接口与CPU核心相连，用于提供每个核心的本地终端管理能力
- 对于不同设备，GIC通过查表的方式得到不同中断处理的函数入口，这个表为中断向量表
- 中断优先级值越低，优先级越高
- FIQ能抢占任意IRQ，FIQ不可抢占

#### 硬中断和软中断

- 硬中断是由外部事件引起的因此具有随机性和突发性；

- 软中断是执行中断指令产生的，无面外部施加中断请求信号，因此中断的发生不是随机的而是由程序安排好的

- 上下半部：

  上半部指的是中断处理程序

  下半部则指的是一些虽然与中断有相关性但是可以延后执行的任务。

  举个例子：在网络传输中，网卡接收到数据包这个事件不一定需要马上被处理，适合用下半部去实现；但是用户敲击键盘这样的事件就必须马上被响应，应该用中断实现。
  两者的主要区别在于：中断不能被相同类型的中断打断，而下半部依然可以被中断打断；中断对于时间非常敏感，而下半部基本上都是一些可以延迟的工作。由于二者的这种区别，所以对于一个工作是放在上半部还是放在下半部去执行，可以参考下面4条：

  1. 如果一个任务对时间非常敏感，将其放在中断处理程序中执行。
  2. 如果一个任务和硬件相关，将其放在中断处理程序中执行。
  3. 如果一个任务要保证不被其他中断（特别是相同的中断）打断，将其放在中断处理程序中执行。
  4. 其他所有任务，考虑放在下半部去执行。
     有写内核任务需要延后执行，因此才有的下半部，进而实现了三种实现下半部的方法。这就是本文要讨论的**软中断**、**tasklet**和**工作队列**。

  下表可以更直观的看到它们之间的关系。

  ![img](https://pic3.zhimg.com/80/v2-a7739295edd6e6c59dcdc0bcc94a71d6_720w.webp)

  - 软中断

    软中断作为下半部机制的代表，是随着SMP（share memory processor）的出现应运而生的，它也是tasklet实现的基础（tasklet实际上只是在软中断的基础上添加了一定的机制）。软中断一般是“可延迟函数”的总称，有时候也包括了tasklet（请读者在遇到的时候根据上下文推断是否包含tasklet）。它的出现就是因为要满足上面所提出的上半部和下半部的区别，使得对时间不敏感的任务延后执行，而且可以在多个CPU上并行执行，使得总的系统效率可以更高。它的特性包括：

    - 产生后并不是马上可以执行，必须要等待内核的调度才能执行。软中断不能被自己打断(即单个cpu上软中断不能嵌套执行)，只能被硬件中断打断（上半部）。

    - 可以并发运行在多个CPU上（即使同一类型的也可以）。所以软中断必须设计为可重入的函数（允许多个CPU同时操作），因此也需要使用自旋锁来保其数据结构。

  - tasklet

    由于软中断必须使用可重入函数，这就导致设计上的复杂度变高，作为设备驱动程序的开发者来说，增加了负担。而如果某种应用并不需要在多个CPU上并行执行，那么软中断其实是没有必要的。因此诞生了弥补以上两个要求的tasklet。它具有以下特性：
    a）一种特定类型的tasklet只能运行在一个CPU上，不能并行，只能串行执行。
    b）多个不同类型的tasklet可以并行在多个CPU上。
    c）软中断是静态分配的，在内核编译好之后，就不能改变。但tasklet就灵活许多，可以在运行时改变（比如添加模块时）。
    tasklet是在两种软中断类型的基础上实现的，因此如果不需要软中断的并行特性，tasklet就是最好的选择。也就是说tasklet是软中断的一种特殊用法，即**延迟情况下的串行执行**。

  - 工作队列

    通常，在工作队列和软中断/tasklet中作出选择非常容易。可使用以下规则：
    \- 如果推后执行的任务需要睡眠，那么只能选择工作队列。
    \- 如果推后执行的任务需要延时指定的时间再触发，那么使用工作队列，因为其可以利用timer延时(内核定时器实现)。
    \- 如果推后执行的任务需要在一个tick之内处理，则使用软中断或tasklet，因为其可以抢占普通进程和内核线程，同时不可睡眠。
    \- 如果推后执行的任务对延迟的时间没有任何要求，则使用工作队列，此时通常为无关紧要的任务。
    实际上，工作队列的本质就是将工作交给内核线程处理，因此其可以用内核线程替换。但是内核线程的创建和销毁对编程者的要求较高，而工作队列实现了内核线程的封装，不易出错，所以我们也推荐使用工作队列。

    ![屏幕截图(75)](操作系统.assets/屏幕截图(75).png)

#### 操作系统如何管理设备

![屏幕截图(76)](操作系统.assets/屏幕截图(76).png)

热插拔：计算机系统中的某些设备会在运行阶段动态接入或断开

驱动模型：LInux Device Driver Model(LDDM)

- 支持电源管理与设备的热拔插
- 利用sysfs向用户空间提供系统信息
- 维护驱动对象的依赖关系与生命周期，简化开发工作
  -  驱动人员只需告诉内核对象间的依赖关系
  -  LDDM启动设备会将依赖对象自动初始化，直到启动条件满足为止

#### 设备发现

- 设备树（Device Tree）：描述硬件信息的数据结构
  - 源码格式（Device Tree Source,DTS)
  - 二进制格式（Device Tree Blob,DTB)



## 系统虚拟化

### 概述

- 系统虚拟化层是软件层，上层是操作系统，底层硬件与上层软件解耦，上层软件可在不同硬件之间切换（硬件之间自由迁移）
- 系统虚拟化优点
  - 利用系统虚拟化可以对服务器进行整合
  - 方便程序开发
    - 调试操作系统
    - 测试应用程序的兼容性

### 什么是系统虚拟化

#### 操作系统中的接口层次

- ISA（Instruction Set Architecture，指令集架构）（可粗略理解为汇编语言），不同CPU的ISA不同

  **硬件和软件的分界线**

  - 用户ISA（用户态和内核态程序都可以使用）
  - 系统ISA（只有内核态程序可以使用，和特殊寄存器相关）

- ABI（Application Binary Interface，应用程序被编译为二进制代码后的接口)，例如调用库

- API（Application Programming Interface，应用程序接口）

  例如用户代码里的函数，包含库的接口ABI和用户API

#### 虚拟机和虚拟机监控器

- 虚拟机监控器控制所有物理资源

![屏幕截图(70)](操作系统.assets/屏幕截图(70).png)

![屏幕截图(74)](操作系统.assets/屏幕截图(74).png)

![屏幕截图(71)](操作系统.assets/屏幕截图(71).png)

![屏幕截图(72)](操作系统.assets/屏幕截图(72).png)

#### 系统虚拟化流程

- 下陷：
  - CPU由用户态切换到内核态的过程
  - 在用户态EL0执行特权指令将陷入EL1的虚拟机监控器中
- 模拟：这些指令的功能都由虚拟机监控器内的函数安全地实现

![屏幕截图(73)](操作系统.assets/屏幕截图(73).png)

![屏幕截图(74)](../../Pictures/Screenshots/屏幕截图(74).png)

#### 可虚拟化架构

当所有敏感指令都是特权指令时，叫做可虚拟化架构

ARM不是严格的可虚拟化架构

### CPU虚拟化

#### 软件虚拟化方法

- 解释执行：使用软件方法一条条对虚拟机代码进行模拟

  虚拟机中有虚拟机指令和虚拟寄存器，指令被模拟器翻译为对应的调用函数，不直接对硬件操作，而是对虚拟机寄存器操作

  - 不区分敏感指令还是其他指令
  - 没有虚拟机指令直接在硬件上执行
  - 解决敏感函数不下陷的问题
  - 模拟不同ISA的虚拟机
  - 任何一条虚拟机指令都会转换成多条模拟指令

- 二进制翻译：

  - 执行前批量翻译虚拟机指令

  - 缓存已翻译完成的指令

  - 使用基本块的翻译粒度，

    每个翻译完的基本块叫做代码补丁

  - 不能处理自修改的代码

  - 中断插入粒度变大

- 半虚拟化

  - 协同设计：将所有不引起下陷的敏感指令替换成超级调用

  - 虚拟机监控器VMM为虚拟机中提供接口，提供系统调用

    （实现这一功能需要更改操作系统代码）

    也就是说，超级调用指令会直接让虚拟机经过操作系统下陷到虚拟机监控器，从虚拟EL0下陷到EL1

- 硬件虚拟化

  - x86引入了root模式和non-root模式

  - ARM进程运行在EL0，操作系统执行在EL1，虚拟机监控器执行在EL2

    

### IO虚拟化

### 内存虚拟化

## 缓存一致性

### 引言

- 多核处理器采用共享内存：不同的核心共享相同的内存资源，核心间可以通过访问同一个地址来共享数据。多核处理器中共享内存的实现是通过添加**多级缓存**来缓存高频访问的数据，从而**降低访问内存的概率**

- 多级缓存结构：

  - 高速缓存中使用缓存行作为最小的操作粒度，大小往往为64字节
  - 每个处理器核心都有自己私有一级缓存
  - 多个核心之间共享一个二级缓存
  - **所有核心共享最末级缓存**（LLC）

- 多级缓存机制下读操作过程：拿到物理地址后，处理器将逐级查找高速缓存中是否保存了该地址对应的缓存行，如果在任意一级高速缓存找到，处理器将直接读取该值，从而避免内存访问

- 多级缓存机制下读操作过程：有两种策略

  - 直写策略：会立即将修改的值刷回内存，同时高速缓存中也保存该值

  - 写回策略：将修改的值暂时存在高速缓存中，但不会立即将修改的值刷回内存，只有出现高速缓存逐出或CPU核心调用写回指令时，修改才会被更新至物理内存

    写回策略会导致缓存不一致问题

- 非一致缓存访问（NUCA）：不同核心访问处于不同位置的缓存行具有不同的访问时延

### 目录式缓存一致性

#### 概述

- 私有高速缓存中的每条缓存行，除了保存了地址和对应的值外，还保存该缓存行的状态（MSI协议中，状态为独占修改（Modified），共享（Shared）或失效（Invalid））
- 全局有一个共享的目录，用于记录所有缓存行所处位置及其状态，每条缓存行对应目录中的一个目录项，每个目录项记录两个内容
  - Dirty Bit（1表示被修改，0表示未修改）：记录是否有处理器已经修改过这个缓存行
  - Bit Vector（拥有者对应位被置为1，其余置为0）：记录缓存行的拥有者
- 全局目录、高速缓存与内存三者之间通过高速内部互联总线相连

#### MSI协议

假设需要访问的缓存行已经在私有高速缓存中

- 独占修改：该状态代表当前缓存行在全局只有本地高速缓存（L1 Cache）中这一份拷贝，因此当前的核心独占该缓存行。

  - 可以直接进行读/写操作，不会触发缓存行的状态变化

- 共享：这个状态代表当前缓存行在全局中可能存在多份拷贝，而且本地的拷贝是有效的。

  - 当前核心能够直接读该缓存行。

  - 如果需要写该缓存行，则当前核心查找全局共享目录，找到所有拥有该缓存行拷贝的核心，并通知这些核心将缓存行状态转换为失效。之后再设置目录中该项的 Dirty

    Bit 为 1，更新拥有者的 Bit Vector。最后将本地的缓存行状态转化为独占修改，方能进行写操作

- 失效：这个状态代表当前缓存行本地的拷贝失效，当前核心不能直接读/写该缓存行

  - 如果需要读该缓存行，则需要在目录中找到拥有该缓存行的核心，向其所要缓存行的数据，同时通知其核心将其缓存行的状态改为共享，之后更新目录中的Dirty Bit为0，并更新拥有者的Bit Vector。最后，在本核心中将拿到的缓存行设置为共享之后，能够读取该缓存行。
  - 如果需要**写**该缓存行，则需要通过目录找到所有拥有缓存行的核心，通知它们将该缓存行状态都改为**失效**。之后才能拿到该缓存行的数据，并更新目录中的状态。最后，将本地的缓存行状态设置为**独占修改**后，方能写该缓存行。

若需要访问的缓存行不在私有高速缓存中时，该核心将查看全局共享目录，检查该缓存行是否在其他核心上。如果其他核心拥有该缓存的拷贝，则处理流程同缓存行为**失效**一致。如果其他核心上也没有，则该次访问为**缓存不命中**（Cache Miss）。此时需要从内存中获取该缓存行，放到本地的高速缓存，同时更新全局的共享目录。而该缓存行状态将根据操作类型为读或写，设置该缓存行状态为**共享**或**独占修改**。

## 网络栈与网络协议

![屏幕截图(77)](操作系统.assets/屏幕截图(77).png)

## 操作系统进阶（jyy网课)

#### 并发编程：

并发编程放弃三大属性：原子性、有序性（执行顺序）、处理器间得到可见性

- 放弃原子性：一条指令或一段代码不再能完整执行，可能执行到一半就被中断改为执行其他线程

- 放弃顺序执行性：在单线程程序中，所有语句是按代码的书写顺序执行的，然而到了并发编程，由于多个线程同时执行代码，程序的顺序执行假设不成立，可能会出现以下情况：

  - 竞态条件：多个线程同时访问同一个共享资源，从而导致结果的不确定性。

  - 内存模型问题：内存模型是描述程序如何访问内存的一种抽象。不同的处理器或缓存可能会对共享内存的读写操作的顺序产生影响，导致程序的执行顺序出现问题。

    - 例：宽松内存模型：

      宽松内存模型是指在多处理器系统中，处理器之间对共享内存的操作的顺序可能会被重排，因此处理器之间的可见性不能被保证。具体来说，如果一个处理器执行了一个写操作，然后执行了一个读操作，如果编译器认为这两个操作的执行顺序对执行结果没有影响，那么这两个操作的顺序可能会被重排，使得其他处理器看到的顺序与执行顺序不同。

      这种内存模型的优点是可以提高系统的性能，因为处理器之间的依赖关系可以被解耦合并行执行，从而提高并行度。但是，由于可见性不能被保证，这种内存模型会带来一些问题。例如，如果一个处理器在写操作之后立即执行了一个读操作，但是另一个处理器看到的顺序是读操作在写操作之前，那么另一个处理器可能会得到一个不正确的结果。

    - 解决方法如：vloatile关键字、锁、原子操作等

  - 死锁和饥饿：由于竞争条件，多个线程可能会陷入死锁或者饥饿状态，无法继续执行下去。

- 放弃处理器间的可见性：

  在多处理器系统中，多个处理器可以同时访问系统的共享内存。

  可见性是指当一个处理器对共享内存进行写入操作后，其他处理器能够立即读取到该写入操作的结果。

  在单处理器系统中，当处理器执行写入操作时，该处理器的缓存会被更新，并且写入会被立即反映在主存储器中。

  但是，在多处理器系统中，每个处理器都有自己的缓存，因此，当一个处理器执行写入操作时，其他处理器可能不会立即看到这个写入操作的结果，因为其他处理器可能仍然从自己的缓存中读取数据。

并发编程还需要考虑编译器的参与：不同编译器会对相同代码做出不同优化，比如对于：

```c
for(int i = 0;i < n;i++)
{
	sum++;
}
```

有的编译器会按代码有运行，一步一步加和，有的编译器会识别出这是循环，直接得出sum+=n
